# 3.2 Attributes Analysis

> 不同的字母个数 T
>
> 元音字母个数 ？

# 4.1 Prediction of Distribution

为了预测未来单词的结果分布，我们首先对过去的数据中的单词结果进行了分类。我们使用 k-means 聚类算法进行分类，此处我们取 k = 15 效果较好。

记所有单词代表的节点集合为 $S$，对于每个节点 $x\in S$， 我们以分数的百分比分布构成的七维向量 $(x_1, x_2, x_3, x_4, x_5, x_6, x_7) $作为 $x$ 的坐标。

对任意两个点 $a, b$ 使用函数：
$$
f(a, b) = \sqrt{\sum_{i=1}^7 (a_i - b_i)^2}
$$
计算两个点的距离，从而根据该距离使用聚类算法。



首先我们需要选择 k 个初始聚类中心，选择规则如下：

1. 随机选择第一个聚类中心，记为$w_1$
2. 假设当前已经选择的聚类中心有$t$个，我们对于每个节点 $x\in S$ 计算：$d_x = \sum_{i=1}^t f(x, w_i)$
3. 对所有节点计算 $d$ 的总和即 $sum = \sum_{x\in S} d_x$
4. 对每个节点计算 $p_x = \frac{d_x}{sum}$ 表示选择节点 $x$ 作为第 $t + 1$ 个聚类中心的概率，容易验证 $\sum_{x\in S} p_x = 1$
5. 根据概率选择下一个聚类中心节点 $w_{t + 1}$
6. 如果 $t + 1 = k$，结束选择，否则返回 2.

这样的选择方式可以避免随机选择初始中心节点导致的局部最优解，从而优化算法效果。



接下来我们进行若干轮迭代，在我们的模型中，迭代 100 轮时分组已经接近收敛。每一轮迭代如下：

1. 对于每一个节点 $x\in S$，我们选择 $k$ 个聚类中心中 $f(x, w_i)$ 最小的中心节点 $w_i$，并把 $x$ 归入聚类 $i$
2. 对于第 $i$ 个聚类，令其中节点集合为 $S_i$，我们对于 $x\in S_i$ 计算 $v_x = \sum_{y\in S_i} f(x, y)$ 。并且选择 $v_x$ 最小的一个 $x$ 作为第 $i$ 个聚类的新中心
3. 返回步骤 1 进行下一轮迭代



迭代结束后，我们便成功将单词结果分成了 k = 15 类。

![WordResultClusters](C:\Users\25673\Desktop\ms\codes\WordResultClusters_final.png) 

我们通过两个典型的统计数据：平均值和方差来展示我们的分类成果。可以看到，平均值和方差接近的单词被分类在了同一个聚类中，因此对于新的单词，我们只需要将其划分到其中一个聚类中，再用聚类内部单词节点的result对新的单词的reslut进行估计即可。